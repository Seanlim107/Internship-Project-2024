{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c25d784",
   "metadata": {},
   "source": [
    "# Inference Testing for Baseline Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4746ebe",
   "metadata": {},
   "source": [
    "## Date: 25th July 2024\n",
    "## Creator: Sean Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb514a",
   "metadata": {},
   "source": [
    "The following notebook displays the baseline model used for distance estimation\n",
    "\n",
    "The code consists of the following pipeline:\n",
    "1) Yolov10 model: Used for detecting objects and is the core of the model\n",
    "2) Config files: Extracts important manually input information such as real dimsnesions and the intrinsic camera matrix\n",
    "- Real dimensions: Estimates in meters (m) used to compare the bounding box vs the real length, height of the object\n",
    "- Intrinsic camera matrix: setting \"use_own\" = True allows manually input variables, while False uses the image dimensions as the camera matrix variables (not recommended)\n",
    "3) The closest distance between two bounding boxes is obtained in pixel length and transforms them to 3D coordinates using computer vision transformations, obtaining the distance between the object and the camera and used as the depth to then get the location of the object (X, Y, Z=depth)\n",
    "4) Euclidean distance between the center points of the boxes are obtained and if it is less then the configurable [safe_distance], a warning will be sent out and lines will be drawn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f876f",
   "metadata": {},
   "source": [
    "### Install Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66532a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLOv10n model\n",
    "from ultralytics import YOLOv10\n",
    "from lib.Dataset import ConstructionDataset\n",
    "from lib.Camera import Camera\n",
    "from lib.utils import parse_yaml, estimate_distance_2d, draw_lines, estimate_distance_centers_3d\n",
    "from lu_vp_detect import VPDetection\n",
    "import torch\n",
    "import os\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# !python --version\n",
    "from lu_vp_detect import VPDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=parse_yaml('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd076e8e",
   "metadata": {},
   "source": [
    "### Prepare dataset from original repo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe458e5a",
   "metadata": {},
   "source": [
    "#### skips if config > YoloPrep > init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python YoloCreate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494df684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Initialization\n",
    "weightpath = os.path.join('runs/detect/train5/weights/best.pt')\n",
    "model = YOLOv10(weightpath)\n",
    "lookup = config['Classes']\n",
    "config_cam = config['Camera']\n",
    "\n",
    "batch_size = 1 # Only for testing purposes\n",
    "safe_distancing = config['General']['safe_dist']\n",
    "consDataset = ConstructionDataset(config, crops=True)\n",
    "\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "            'shuffle':True,\n",
    "            'num_workers': 6}\n",
    "seed = config['General']['seed']\n",
    "if seed is not None:\n",
    "    torch.manual_seed(config['General']['seed'])\n",
    "generator = data.DataLoader(consDataset, **params)\n",
    "\n",
    "# Drawing parameters\n",
    "Color_palette = 255 * np.eye(3)\n",
    "config_cam = config['Camera']\n",
    "config_vp = config['VP_Detector']\n",
    "remove_fisheye=config_cam['remove_fisheye']\n",
    "# BGR format\n",
    "# First row is red, second green, third blue\n",
    "Color_palette = Color_palette[:, ::-1].astype(int).tolist()\n",
    "\n",
    "length_thresh = config_vp['length_thresh']\n",
    "principal_point = config_vp['principal_point']\n",
    "focal_length = config_vp['focal_length']\n",
    "seed = config['General']['seed'] # Or specify whatever ID you want (integer)\n",
    "\n",
    "vpd = VPDetection(length_thresh, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3459a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generator\n",
    "generator_iter = iter(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b0565",
   "metadata": {},
   "source": [
    "## Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, local_image, local_image_tensor = next(generator_iter)\n",
    "temp_img = local_image_tensor[0]\n",
    "temp_img_ori = np.array(local_image[0])\n",
    "\n",
    "print(temp_img_ori.shape)\n",
    "\n",
    "cam = Camera(use_own = config_cam['use_own'], img=temp_img_ori, distortion_coef=config_cam['distortion_coef'], fx=config_cam['fx'], fy=config_cam['fy'], cx=config_cam['cx'], cy=config_cam['cy'])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    results = model(temp_img)\n",
    "\n",
    "#Predicted coordinates of box (top left, bottom right)\n",
    "list_boxes = results[0].boxes.xyxy\n",
    "\n",
    "#List of detected classes\n",
    "detected_classes = results[0].boxes.cls\n",
    "\n",
    "\n",
    "# Plot original Image with Yolo Detection    \n",
    "img = results[0].plot()\n",
    "\n",
    "#Draw lines and send warning if a distance is lower than safe distance\n",
    "if(len(list_boxes)>1 and 0 in detected_classes):\n",
    "    list_conf = results[0].boxes.conf\n",
    "    list_workers = [(i, detected_classes[i].item(), list_boxes[i], list_conf[i].item()) for i in range(len(detected_classes)) if int(detected_classes[i]) == 0]\n",
    "    list_nonworkers = [(i, detected_classes[i].item(), list_boxes[i], list_conf[i].item()) for i in range(len(detected_classes)) if int(detected_classes[i]) != 0]\n",
    "\n",
    "##################################################################################################################################################\n",
    "# List workers and List Non Workers have the following:\n",
    "# (0: index wrt detected objects in YOLO accordingly, 1: Class in int format, 2: xyxy, 3: Confidence Score for ease of labelling when plotting)\n",
    "##################################################################################################################################################\n",
    "\n",
    "vps = vpd.find_vps(temp_img_ori)\n",
    "print(vps)\n",
    "print(vpd.vps_2D)\n",
    "\n",
    "vp1, vp2, vp3 = vpd.vps_2D[:3]\n",
    "\n",
    "# draw_grid(img, vp1, vp2, vp3, Color_palette)\n",
    "\n",
    "for worker in list_workers:\n",
    "    for nonworker in list_nonworkers:\n",
    "        length= estimate_distance_2d(worker[2], nonworker[2])\n",
    "        # print(length)\n",
    "        hazard = lookup[nonworker[1]]['name']\n",
    "        worker_dim = lookup[worker[1]]['dimensions']\n",
    "        hazard_dim = lookup[nonworker[1]]['dimensions']\n",
    "        \n",
    "        worker_3d_coords = cam.find_real_coords(worker[2], worker_dim)\n",
    "        hazard_3d_coords = cam.find_real_coords(nonworker[2], hazard_dim)\n",
    "        distance = estimate_distance_centers_3d(worker_3d_coords, hazard_3d_coords)\n",
    "        \n",
    "        \n",
    "        # print(f'3D Coordinates of worker: ,{worker[3]:.2f},{worker_3d_coords}')\n",
    "        # print(f'3D Coordinates of , {hazard}: , {nonworker[3]:.2f}, {hazard_3d_coords}')\n",
    "        # print(f'Distance = {distance:.2f}m')\n",
    "        \n",
    "        if(distance < safe_distancing):\n",
    "            print(f'Unsafe distancing between worker:{worker[3]:.2f} and {hazard}:{nonworker[3]:.2f}, Distance={distance:.2f}m')\n",
    "            print('3D Coordinates of worker: ',worker[3],worker_3d_coords)\n",
    "            print('3D Coordinates of ', hazard,': ', nonworker[3], hazard_3d_coords)\n",
    "            color = (255,0,0)\n",
    "        else:\n",
    "            color = (255,255,255)\n",
    "        \n",
    "        \n",
    "        draw_lines(worker[2], nonworker[2], img, distance, color)\n",
    "        \n",
    "print('__________________________________________________________________________')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 16), dpi=80)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ffc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
